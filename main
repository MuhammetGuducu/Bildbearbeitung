#include <cstdio>
#include <iostream>
#include <opencv2/videoio.hpp>
#include "utility.hpp"
#include "depthai/depthai.hpp"
#include <algorithm>
#include <numeric>
#include <opencv2/core.hpp>
#include <string>
#include <opencv2/highgui.hpp>
#include <opencv2/imgproc.hpp>

using namespace std;
using namespace cv;


void evaluateFrames(cv::Mat& binaryBild, cv::Mat& rgbFrame, cv::Mat& depFrame) {
// Region Labeling
    cv::Mat labels, stats, center;
    int numLabels = cv::connectedComponentsWithStats(binaryBild, labels, stats, center);
    int label;
// Größtes Segment auswählen
    int largestSegmentLabel = 0;
    int largestSegmentArea = 0;
    for (label = 1; label < numLabels; label++) {
        int area = stats.at<int>(label, cv::CC_STAT_AREA);
        cout << area << endl;
        if (area > largestSegmentArea) {
            largestSegmentArea = area;
            largestSegmentLabel = label;
        }
    }
    cv::Mat frame;
// Einzeichnen des roten Rechtecs in das Binärbild
    cv::Mat largestSegmentMask = (labels == largestSegmentLabel);
    cv::Mat BildFrame = depFrame;

    int left = stats.at<int>(largestSegmentLabel, cv::CC_STAT_LEFT);
    int top = stats.at<int>(largestSegmentLabel, cv::CC_STAT_TOP);
    int width = stats.at<int>(largestSegmentLabel, cv::CC_STAT_WIDTH);
    int height = stats.at<int>(largestSegmentLabel, cv::CC_STAT_HEIGHT);

    cvtColor(binaryBild, binaryBild, cv::COLORMAP_RAINBOW);
    cv::rectangle(binaryBild, cv::Rect(left, top, width, height), cv::Scalar(0, 0, 255), 3); //cv::Mat largestSegmentOutline;
    cv::imshow("binaryimage_rectangle", binaryBild);



// RGB TEXT
    double durchschnitt = 0;
    int zaehler = 0;
    for (int i = 0; i < binaryBild.rows; ++i) {
        for (int j = 0; j < binaryBild.cols; ++j) {
            if (labels.at<int>(i, j) == largestSegmentLabel) {
                durchschnitt += BildFrame.at<uchar>(i, j);
                zaehler++;
            }
        }
    }

    if (zaehler > 0) {
        durchschnitt /= zaehler;
    }


    static int statLeft = left;
    static int statTop = top;
    static double statDeptDurchschnitt = durchschnitt;

    int differenzLeft = abs(left - statLeft);
    int differenzTop = abs(top - statTop);
    double differenzDepth = abs(durchschnitt - statDeptDurchschnitt);

    int thresholdX = 20;
    int thresholdY = 20;
    double thresholdDepth = 3.0;
    cv::Mat bildFarben;
    cvtColor(rgbFrame, bildFarben, COLOR_GRAY2BGR);

    if (differenzLeft > thresholdX || differenzTop > thresholdY || differenzDepth > thresholdDepth) {
        cout << "Folgende Bewegung erkannt: ";

        if (differenzDepth > thresholdDepth)
        {
            cout << "Tiefe (" << (durchschnitt > statDeptDurchschnitt ? "vor" : "zuruck") << "), ";
        }

        if (differenzTop > thresholdY)
        {
            cout << "Hoch-Runter, ";
        }

        if (differenzLeft < thresholdX)
        {
            cout << "Links-Rechts ";
        }

        cout << "\n";


        string movementText = "Folgende Bewegung erkannt: ";
        if (differenzDepth > thresholdDepth) {
            movementText += (durchschnitt > statDeptDurchschnitt ? "vor" : "zuruck");
        }


        if (differenzTop > thresholdY)
        {
            movementText += "Hoch-Runter, ";
        }

        if (differenzLeft > thresholdX)
        {
            movementText += "Links-Rechts ";
        }

        putText(rgbFrame, movementText, Point(10, 30), FONT_HERSHEY_SIMPLEX, 1, Scalar(0, 0, 255), 2);

        imshow("RGB Textauswertung", rgbFrame);


    }
    else {
        putText(rgbFrame, "Keine Bewegung erkannt", Point(10, 30), FONT_HERSHEY_SIMPLEX, 1, Scalar(0, 0, 255), 2);
        imshow("RGB Textauswertung", rgbFrame);


    }

    statLeft = left;
    statTop = top;
    statDeptDurchschnitt = durchschnitt;
}


cv::Mat histogrammRechner(const cv::Mat& bild, cv::Mat& rgb) {
    float* histogram_arr = new float[256] {0};

    for(int y=0; y<bild.rows; y++)
        for(int x=0; x<bild.cols; x++){
            histogram_arr[bild.at<uchar>(y,x)] +=1;
        }
    cv::Mat hist(750,750, CV_8UC3, cv::Scalar(0,0,0));
    cv::Mat blur(256, 1, CV_32FC1, histogram_arr);
    cv::GaussianBlur(blur, blur, cv::Size(19,19),2.0);
    int max = *std::max_element(histogram_arr, histogram_arr + 256);

    for (int i = 0; i < 254; i++) {
        cv::line(hist,
                 cv::Point(i, 750 - cvRound((int) ((double)histogram_arr[i] / max*750))) ,
                 cv::Point(i+1, 750 - cvRound((int)((double) histogram_arr[i+1] /max*750))),
                 cv::Scalar(255,255 ,255), 1,0,0);

    }


// höchsten Wert
    double ersterWert200;
    minMaxLoc(bild, 0, &ersterWert200);

// erster Wert, der höher als 200 ist
    int ZwischenWert = (ersterWert200);
    while (ZwischenWert >= 0 && blur.at<float>(ZwischenWert) <= 200) {
        ZwischenWert--;
    }


// hinteren Maximum
    int hinteresMax = ZwischenWert;
    while (hinteresMax > 1 && blur.at<float>(hinteresMax - 1) >= blur.at<float>(hinteresMax)) {
        hinteresMax--;
    }

// Suche nach dem davor liegenden lokalen Minimum
    int lokalesMin = hinteresMax;
    while (lokalesMin >= 0 && blur.at<float>(lokalesMin - 1) <= blur.at<float>(lokalesMin)) {
        lokalesMin--;
    }

// Zeichnen Sie die beiden gefundenen Werte als Balken in Ihr Histogrammbild ein
    cv::line(hist, cv::Point(ZwischenWert, 0), cv::Point(ZwischenWert, 750), cv::Scalar(0, 0, 255), 1);
    cv::line(hist, cv::Point(lokalesMin, 0), cv::Point(lokalesMin, 750), cv::Scalar(255, 0, 0), 1);


    cv::imshow("Histogramm", hist);

    cv::Mat binaryimage;
    cv::threshold(bild,binaryimage,lokalesMin,255,cv::THRESH_BINARY);
    cv::imshow("binaryimage", binaryimage);
    Mat tiefenCopy = bild.clone();
    evaluateFrames(binaryimage, tiefenCopy, rgb);

    return binaryimage;
}




// Optional. If set (true), the ColorCamera is downscaled from 1080p to 720p.
// Otherwise (false), the aligned depth is automatically upscaled to 1080p
static std::atomic<bool> downscaleColor{true};
static constexpr int fps = 30;
// The disparity is computed at this resolution, then upscaled to RGB resolution
static constexpr auto monoRes = dai::MonoCameraProperties::SensorResolution::THE_720_P;

static float rgbWeight = 0.4f;
static float depthWeight = 0.6f;

/*static void updateBlendWeights(int percentRgb, void* ctx) {
rgbWeight = float(percentRgb) / 100.f;
depthWeight = 1.f - rgbWeight;
}
*/
int main() {
    using namespace std;
    cv::VideoWriter rgbVod, depthVod;
    int mode = 0;
// Überprüfen Anzahl der Übergabeparameter
    while(mode < 1 || mode > 3)
    {
        cout <<"Bitte geben Sie einen Übergabeparameter (1-3) ein: " ;
        cin >> mode;
    }

// Create pipeline
    dai::Pipeline pipeline;
    dai::Device device;
    std::vector<std::string> queueNames;

// Define sources and outputs
    auto camRgb = pipeline.create<dai::node::ColorCamera>();
    auto left = pipeline.create<dai::node::MonoCamera>();
    auto right = pipeline.create<dai::node::MonoCamera>();
    auto stereo = pipeline.create<dai::node::StereoDepth>();

    auto rgbOut = pipeline.create<dai::node::XLinkOut>();
    auto depthOut = pipeline.create<dai::node::XLinkOut>();

    rgbOut->setStreamName("rgb");
    queueNames.push_back("rgb");
    depthOut->setStreamName("depth");
    queueNames.push_back("depth");

// Properties
    camRgb->setBoardSocket(dai::CameraBoardSocket::CAM_A);
    camRgb->setResolution(dai::ColorCameraProperties::SensorResolution::THE_1080_P);
    camRgb->setFps(fps);
    if(downscaleColor) camRgb->setIspScale(2, 3);
// For now, RGB needs fixed focus to properly align with depth.
// This value was used during calibration
    try {
        auto calibData = device.readCalibration2();
        auto lensPosition = calibData.getLensPosition(dai::CameraBoardSocket::CAM_A);
        if(lensPosition) {
            camRgb->initialControl.setManualFocus(lensPosition);
        }
    } catch(const std::exception& ex) {
        std::cout << ex.what() << std::endl;
        return 1;
    }

    stereo->setExtendedDisparity(false);
    stereo->initialConfig.setMedianFilter(dai::MedianFilter::KERNEL_7x7);

    auto config= stereo->initialConfig.get();
    config.postProcessing.thresholdFilter.minRange = 500;
    config.postProcessing.thresholdFilter.maxRange = 1000;

    stereo->initialConfig.setConfidenceThreshold(200);
    stereo->initialConfig.set(config);

    left->setResolution(monoRes);
    left->setCamera("left");
    left->setFps(fps);
    right->setResolution(monoRes);
    right->setCamera("right");
    right->setFps(fps);


// stereo->setDefaultProfilePreset(dai::node::StereoDepth::PresetMode::HIGH_DENSITY);
// LR-check is required for depth alignment
    stereo->setLeftRightCheck(true);
    stereo->setDepthAlign(dai::CameraBoardSocket::CAM_A);

// Linking
    camRgb->isp.link(rgbOut->input);
    left->out.link(stereo->left);
    right->out.link(stereo->right);
    stereo->disparity.link(depthOut->input);

    if (mode == 1) {
        cout << "Hier findet die Auswertung des Live-Kamerabilds statt" << endl;
    }

    if(mode == 2) {
        cout << "Hier findet die Auswertung des Live-Kamerabilds statt" << endl;
        rgbVod.open("rgb.avi", 0, fps, cv::Size(1280, 720));
        depthVod.open("depth.avi", 0, fps, cv::Size(1280, 720));

        if(!rgbVod.isOpened()) {
            cout << "Fehler beim Öffnen des RGB Videowriters" << endl;
            return 1;
        }
        if(!depthVod.isOpened()) {
            cout << "Fehler beim Öffnen des Depth Videowriters" << endl;
            return 1;
        }
    }
    if (mode == 3) {
//histogrammRechner();
        cout << "Hier findet die Auswertung auf dem aufgezeichneten Video statt" << endl;
        cv::VideoCapture depthVid("depth.avi");
        cv::VideoCapture rgbVid("rgb.avi");
        if(!depthVid.isOpened()){
            cout << "Fehler beim öffnen der Depth Video Datei" << endl;
            return -1;
        }
        if(!rgbVid.isOpened()){
            cout << "Fehler beim öffnen der RGB Video Datei" << endl;
            return -1;
        }
        while(1){
            cv::Mat frameDepth;
            cv::Mat frameRGB;

            if (frameDepth.empty())
                break;
            imshow( "FrameDepth", frameDepth );

            if (frameRGB.empty())
                break;
            imshow( "FrameRBG", frameRGB );

// esc to exit
            char c=(char)cv::waitKey(25);
            if(c==27)
                break;
        }

// Schließe alles
        depthVid.release();
        rgbVid.release();
        cv::destroyAllWindows();
        return 0;
    }


// Connect to device and start pipeline
    device.startPipeline(pipeline);

// Sets queues size and behavior
    for(const auto& name : queueNames) {
        device.getOutputQueue(name, 4, false);
    }


    std::unordered_map<std::string, cv::Mat> frame;

    auto rgbWindowName = "rgb";
    auto depthWindowName = "depth";
// auto blendedWindowName = "rgb-depth";
    cv::namedWindow(rgbWindowName);
    cv::namedWindow(depthWindowName);
// cv::namedWindow(blendedWindowName);
// int defaultValue = (int)(rgbWeight * 100);
// cv::createTrackbar("RGB Weight %", blendedWindowName, &defaultValue, 100, updateBlendWeights);

    if(mode == 1){
        cout << "Auswerten erfolgreich" << endl;

        while(true) {
            std::unordered_map<std::string, std::shared_ptr<dai::ImgFrame>> latestPacket;

            auto queueEvents = device.getQueueEvents(queueNames);
            for(const auto& name : queueEvents) {
                auto packets = device.getOutputQueue(name)->tryGetAll<dai::ImgFrame>();
                auto count = packets.size();
                if(count > 0) {
                    latestPacket[name] = packets[count - 1];
                }

/*if(eingabe == 2 && name == "rgb") {
aufRGB.write(frame[name]);
}
if(eingabe == 2 && name == "depth") {
aufDep.write(frame[name]);    if (latestPacket.find(name) != latestPacket.end()) {
                    if (name == depthWindowName) {
                        frame[name] = latestPacket[name]->getFrame();
                        auto maxDisparity = stereo->initialConfig.getMaxDisparity();
                        stereo->setExtendedDisparity(true);
// Optional, extend range 0..95 -> 0..255, for a better visualisation
// if (1) frame[name].convertTo(frame[name], CV_8UC1, 255. / maxDisparity);
// Optional, apply false colorization
// if (1) cv::applyColorMap(frame[name], frame[name], cv::COLORMAP_JET);
                    } else {
                        frame[name] = latestPacket[name]->getCvFrame();
}*/

            }

            for(const auto& name : queueNames) {
                if(latestPacket.find(name) != latestPacket.end()) {
                    if(name == depthWindowName) {
                        frame[name] = latestPacket[name]->getFrame();

                        auto maxDisparity = stereo->initialConfig.getMaxDisparity();
                        if(1) frame[name].convertTo(frame[name], CV_8UC1, 255. / maxDisparity);
                    } else {
                        frame[name] = latestPacket[name]->getCvFrame();
                    }


                    if(name == "depth") {
                        histogrammRechner(frame["depth"], frame["rgb"]);
                        cv::imshow(name, frame[name]);
                    }
                }
            }


            int key = cv::waitKey(1);
            if(key == 'q' || key == 'Q') {
                rgbVod.release();
                depthVod.release();
                return 0;
            }
        }


    }
    else if(mode == 2){

        rgbVod.open("RGB.avi", 0,fps, cv::Size(1280,720));
        depthVod.open("DEPTH.avi", 0,fps, cv::Size(1280,720),false);


        if(!depthVod.isOpened() || !depthVod.isOpened()){
            cerr << "Aufzeichnung fehlgeschlagen!" << endl;
            return 0;
        }

        while(true) {
            std::unordered_map<std::string, std::shared_ptr<dai::ImgFrame>> latestPacket;

            auto queueEvents = device.getQueueEvents(queueNames);
            for(const auto& name : queueEvents) {
                auto packets = device.getOutputQueue(name)->tryGetAll<dai::ImgFrame>();
                auto count = packets.size();
                if(count > 0) {
                    latestPacket[name] = packets[count - 1];
                }
            }

            int counter;

            for (const auto &name: queueNames) {
                if (latestPacket.find(name) != latestPacket.end()) {
                    if (name == depthWindowName) {
                        frame[name] = latestPacket[name]->getFrame();
                        auto maxDisparity = stereo->initialConfig.getMaxDisparity();
                        stereo->setExtendedDisparity(true);
// Optional, extend range 0..95 -> 0..255, for a better visualisation
// if (1) frame[name].convertTo(frame[name], CV_8UC1, 255. / maxDisparity);
// Optional, apply false colorization
// if (1) cv::applyColorMap(frame[name], frame[name], cv::COLORMAP_JET);
                    } else {
                        frame[name] = latestPacket[name]->getCvFrame();
                    }
                    if (mode == 2 && name == "rgb") {
                        if (!rgbVod.isOpened())
                            rgbVod.open("output.avi",cv::VideoWriter::fourcc('M', 'J', 'P', 'G'), fps,
                                        cv::Size(frame[name].size().width, frame[name].size().height), 1);
                        rgbVod.write(frame[name]);
                    }

                    if (mode == 2 && name == "depth") {
                        if (!depthVod.isOpened())
                            depthVod.open("output1.avi", 0, fps,cv::Size(frame[name].size().width, frame[name].size().height), 0);
                        depthVod.write(frame[name]);
                    }
                    if ((mode == 1 || mode == 3) && name == "depth") {

                    }
                    cv::imshow(name, frame[name]);

                }
            }


/* // Blend when both received
if(frame.find(rgbWindowName) != frame.end() && frame.find(depthWindowName) != frame.end()) {
// Need to have both frames in BGR format before blending
if(frame[depthWindowName].channels() < 3) {
cv::cvtColor(frame[depthWindowName], frame[depthWindowName], cv::COLOR_GRAY2BGR);
}
cv::Mat blended;
cv::addWeighted(frame[rgbWindowName], rgbWeight, frame[depthWindowName], depthWeight, 0, blended);
cv::imshow(blendedWindowName, blended);
frame.clear();
}
*/
            int key = cv::waitKey(1);
            if(key == 'q' || key == 'Q') {
                return 0;
            }
        }
        return 0;
    }
}
